推荐算法也可以很简单
https://www.zhihu.com/column/c_1330637706267734016

【推荐算法(一)——FM因式分解】
优点：
将二阶交叉特征考虑进来，提高模型的表达能力；
引入隐向量，缓解了数据稀疏带来的参数难训练问题；
模型复杂度保持为线性，并且改进为高阶特征组合时，仍为线性复杂度，有利于上线应用。
缺点：
虽然考虑了特征的交叉，但是表达能力仍然有限，不及深度模型；
同一特征与不同特征组合使用的都是同一隐向量，违反了特征与不同特征组合可发挥不同重要性的事实。

【推荐算法(二)——FFM】
FFM（Field-aware Factorization Machine）是 FM 的改进版
优点：
引入field域的概念，让某一特征与不同特征做交互时，可发挥不同的重要性，提升模型表达能力；
可解释性强，可提供某些特征组合的重要性。
缺点：
复杂度高，不适用于特征数较多的场景。

【推荐算法(三)——Wide&Deep】
需要注意的是，两部分的输入不同：
Wide 部分：Dense Features + Sparse Features（onehot 处理）+  特征组合
Deep 部分：Dense Embeddings (Sparse Features 进行 onehot + embedding 处理)

优点:
1 结构简单，复杂度低，目前在工业界仍有广泛应用；
2 线性模型与深度模型优势互补，分别提取低阶与高阶特征交互信息，兼顾记忆能力与泛化能力；
3 线性部分为广义线性模型，可灵活替换为其他算法，比如 FM，提升 wide 部分提取信息的能力。
缺点：
1 深度模型可自适应的进行高阶特征交互，但这是隐式的构造特征组合，可解释性差；
2 深度模型仍需要人工特征来提升模型效果，只是需求量没有线性模型大。
