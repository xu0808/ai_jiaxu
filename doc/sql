1、计算分组count的总和
from pyspark.sql import functions as F
total = df2.agg(F.sum('count')).first()[0]

2、数值格式化
concat(format_number(100*count/{1}, 3),'%')
sql3 = "select concat({0}*setp_num + 1,'~',{0}*(setp_num+1)) as bucket,format_number(100*count/{1}, 5) as percent from data2".format(


3、组内排序(最值)
select a.Classid,a.English from
(select Classid,English,row_number() over(partition by Classid order by English desc) as n
from CJ) a where n<=2

4、组内合并
select userId,collect_list(emb) emb_list from temp grop by userId

5、数组拆分多行
select pair[0] as pair_0,pair[1] as pair_1 from temp lateral view explode(seqs_pair(item_seq)) as pair